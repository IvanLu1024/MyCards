# 一、Zookeeper的安装（以三台机器为例）

## 1. 首先配置好JDK

## 2. 下载并解压（以3.4.5版本为例）

```bash
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz
tar -zxvf zookeeper-3.4.5.tar.gz -C ./zookeeper
```

## 3. 配置环境变量

```bash
vim /etc/profile
## 添加以下内容
export ZOOKEEPER_HOME=/home/hadoop/zookeeper #your zookeeper root dir
export PATH=$PATH:$ZOOKEEPER_HOME/bin
## 重新编译文件
source /etc/profile
```

## 4. 修改配置文件

```bash
##进入zookeeper目录下的conf
cd conf
cp zoo_sample.cfg zoo.cfg
vim zoo.cfg
##添加以下内容
dataDir=/home/hadoop/zookeeper/data
dataLogDir=/home/hadoop/zookeeper/log
server.1=slave1:2888:3888 (主机名, 心跳端口、数据端口)
server.2=slave2:2888:3888
server.3=slave3:2888:3888
```

## 5. 下发到其他机器上

```bash
scp -r /home/hadoop/zookeeper hadoop@slave2:/home/hadoop/
scp -r /home/hadoop/zookeeper hadoop@slave3:/home/hadoop/
```

## 6. 修改其他机器上的配置文件

到slave2上：修改myid为：2

到slave3上：修改myid为：3

## 7. 启动并查看

```bash
##每台机器都执行该操作
./zkServer.sh start
##查看集群状态
jps #查看是否存在QuorumPeerMain进程
zkServer.sh status #查看集群状态，主从信息
```

# 二、Kafka的安装（以2.11-1.0.0版本为例）

## 1. 下载并解压，首先必须安装zookeeper

```bash
wget https://archive.apache.org/dist/kafka/1.0.0/kafka_2.11-1.0.0.tgz
tar -zxvf kafka_2.11-1.0.0.tgz
```

## 2. 配置

进入config，修改server.properties文件，添加如下内容

```properties
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0
port=9092
host.name=192.168.89.128(本机的ip) 
############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=localhost:2181（配置你的zookeeper服务器）

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000
```



## 3. 启动

进入bin目录，使用jps命令查看是否正常启动

```bash
./kafka-server-start.sh  ../config/server.properties > /dev/null 2>&1 &
```

## 4. 一些其他命令

1. 创建topic

bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic test

2. 列出所有topic

bin/kafka-topics.sh --list --zookeeper localhost:2181

3. 向topic中写入数据

bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

4. 消费数据

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning

或

bin/kafka-console-consumer.sh --bootstrap-server localhost:2181 --topic test --from-beginning

5. 查看指定topic的详情

bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test

# 三、Hadoop的安装

## 1. 下载并解压

```bash
wget https://archive.apache.org/dist/hadoop/hadoop-2.8.0.tar.gz
tar -zxvf hadoop-2.8.0.tar.gz
```

## 2. 配置

到/etc/hadoop/目录下：

- hadoop_env.sh:

```shell
export JAVA_HOME=/home/ivan/apps/java/jdk1.8.0_211(环境变量中配置的JAVA_HOME的地址)
```

- core-site.xml:

```xml
<configuration>
<property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
<property>
<name>hadoop.tmp.dir</name>
<value>/home/ivan/apps/hadoop-2.8.1/data/tmp(临时文件的目录)</value>
</property>
</configuration>
```

- hdfs-site.xml:

```xml
<configuration>
 <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

## 3. 启动

格式化文件系统（仅第一次执行即可，不要重复执行）
进入bin目录：./hdfs namenode –format

进入sbin目录
./start-dfs.sh
验证是否成功启动jps命令，观察是否存在以下内容：

DataNode
SecondNode
NameNode

## 4. 访问Web

http://hostname:50070

# 四、HBase的安装（以版本1.2.6为例）

HBase的安装的前提是成功安装好了Hadoop中的hdfs。

## 1. 下载并解压

```bash
wget https://archive.apache.org/dist/hbase/1.2.6/hbase-1.2.6-bin.tar.gz
tar -zxvf hbase-1.2.6-bin.tar.gz 
```

## 2. 配置

### 2.1 配置hbase-env.sh

```shell
export JAVA_HOME=/home/ivan/apps/java/jdk1.8.0_211
export HBASE_MANAGES_ZK=false
```

### 2.2 配置hbase-site.xml

```xml
<configuration>
  <property>
    <name>hbase.tmp.dir</name>
    <value>/home/ivan/apps/hbase-1.2.6/data/tmp</value>
  </property>
    <property>
    <name>hbase.rootdir</name>
    <value>hdfs://localhost:9000/hbase</value>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>localhost</value>
  </property>
</configuration>
```

### 2.3 配置regionservers

```
localhost
```

## 3. 启动服务

```bash
./start-hbase.sh
# 使用jps验证是否存在HRegionServer和HMaster
jps
```

## 4. 访问Web

http://hostname:16010

> 早期版本端口号为：60010
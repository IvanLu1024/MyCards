## 1. windows下运行客户端（Hadoop）程序报错：Failed to locate the winutils binary in the hadoop binary path

由于win机器并没有配置该环境变量，所以程序报 null\bin\winutils.exe

### 解决方法：

1. 下载winutils的windows版本 
   　　GitHub上，有人提供了winutils的windows的版本，项目地址是：<https://github.com/srccodes/hadoop-common-2.2.0-bin>,直接下载此项目的zip包，下载后是文件名是hadoop-common-2.2.0-bin-master.zip,随便解压到一个目录
2. 配置环境变量 
   　　增加用户变量HADOOP_HOME，值是下载的zip包解压的目录，然后在系统变量path里增加%HADOOP_HOME%\bin 即可。　　
3. 重启开发工具idea，再次运行程序，正常执行。

## 2. java访问HBase卡住很久以后，并报错：Failed to get region location

如果在HBase Cluster中RegionServer是通过hostname配置的，**那么在App测试机（即Windows中）上一定要修改/etc/hosts**，把RegionServer的IP和hostname映射对应上去，不然Table.put()会由于获取不到RegionServer而卡死

仅仅是因为linux（centos）的hosts的问题，是由于默认hosts中的local.localdomain。

### 解决方法：

1. 客户端里（即你的程序所在的计算机）里，要修改etc/hosts文件，把你的HBase集群的服务器Master的主机名加进去；
2. 将local.localdomain全部去除，并添加新的主机映射：

```
#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
#::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.89.128  cent1
127.0.0.1 localhost
```

3. 服务器上，hbase的conf/regionservers一定要配置hadoop主机名；
4. 服务器上，zk的conf/zoo.cfg添加hadoop主机名。